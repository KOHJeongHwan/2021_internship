{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('news': conda)"
  },
  "interpreter": {
   "hash": "72dd90e7b1ce7a48b28470bb78287cf3415c6e0697c2ed54321a33a92b38e591"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 내가 짠 뉴스 유사도 비교 코드\n",
    "\n",
    "최종본은 main(최종).ipynb 입니다.\n",
    "\n",
    "\n",
    "### 최종본과 다른점\n",
    "\n",
    "TfidfVectorizer 를 활용하고 안하고의 차이!\n",
    "\n",
    "또한 100% 활용한 최종본이 결과가 좀 더 좋게 나왔다.\n",
    "\n",
    "이유는 내가 구현한 코드는 정규화 작업이 없는데 모듈에는 있다고한다.(L2)\n",
    "\n",
    "그 차이가 결과를 만든것 같다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 64122 entries, 0 to 64121\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   CNo       64122 non-null  object\n 1   Subject   64122 non-null  object\n 2   Contents  64122 non-null  object\ndtypes: object(3)\nmemory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./pretreatment_data/yeonhap_pre.csv', names=['CNo', 'Subject', 'Contents'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9747 entries, 0 to 9746\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   CNo       9747 non-null   object\n 1   Subject   9747 non-null   object\n 2   Contents  9747 non-null   object\ndtypes: object(3)\nmemory usage: 228.6+ KB\n"
     ]
    }
   ],
   "source": [
    "et_df = pd.read_csv('./pretreatment_data/etoday_pre.csv', names=['CNo', 'Subject', 'Contents'])\n",
    "et_df.info()"
   ]
  },
  {
   "source": [
    "### 연합 뉴스 idf 값을 저장하기 위한 자체 코드\n",
    "\n",
    "이투데이 뉴스의 tf-idf 를 구하려면 연합 뉴스로 만든 idf 값이 필요하다. 그래서 만듦.\n",
    "\n",
    "하지만 TfidfVectorizer 에 있는 기능이었다.\n",
    "\n",
    "정확히는 연합 뉴스로 학습한 값으로 이투데이 뉴스를 (idf)계산가능 했던것~\n",
    "\n",
    "이젠 알았음\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term, document):\n",
    "    # document 에서 term 의 등장 횟수를 count\n",
    "    return document.count(term)\n",
    "\n",
    "def idf(term, documents):\n",
    "    # doc_list 에서 term 이 등장한 문서 수를 count\n",
    "    \n",
    "    # 함수가 돌 때마다 초기화\n",
    "    dfn = 0\n",
    "    for doc in documents:\n",
    "        # 각 문서마다 해당 언어가 있는지 확인\n",
    "        if term in doc:\n",
    "            dfn = dfn + 1\n",
    "    return log(len(documents)/(dfn+1))\n",
    "    \n",
    "def tfidf(term, docu):\n",
    "    # tf * idf\n",
    "    return tf(term, docu)*idf(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64122, 65825)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df['Contents'])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "source": [
    "token_list_all 에는 연합 뉴스로 구성된 단어들이 존재한다.\n",
    "\n",
    "단어 집합이라 중복 없고, 딕셔너리 형태로 (단어, 순번) 이 저장되어있음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "65825"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 토큰(단어) 를 아이템 오름차순으로 키를 정렬 토큰(단어) 를 아이템 오름차순으로 키를 정렬\n",
    "token_list_all = sorted(tfidf.vocabulary_.items(), key = lambda item: item[1])\n",
    "len(token_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, _ in token_list_all:\n",
    "    print(token)\n",
    "    break"
   ]
  },
  {
   "source": [
    "idf_dit_all 은 미리 계산한 연합뉴스의 idf matrix임.\n",
    "\n",
    "딕셔너리 형태로 저장했고, (단어, idf 값) 이런 형식이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"idf_dit_all.pickle\", 'rb') as handle:\n",
    "    dit_all = pickle.load(handle) \n",
    "\n",
    "def aaa(num):\n",
    "    vs_list = []\n",
    "\n",
    "    doc = et_df.iloc[num]['Contents']\n",
    "    vs_list.append([])\n",
    "    for token, _ in token_list_all:\n",
    "        vs_list[-1].append( tf(token, doc)*dit_all[token] )\n",
    "\n",
    "    cosine_matrix = cosine_similarity(vs_list, tfidf_matrix)\n",
    "\n",
    "    # news title과 id를 맵핑할 dictionary를 생성\n",
    "    news2id = {}\n",
    "    for i, c in enumerate(df['CNo']):\n",
    "        news2id[i] = c\n",
    "\n",
    "    # id와 news title를 매핑할 dictionary를 생성\n",
    "    id2news = {}\n",
    "    for i, c in news2id.items():\n",
    "        id2news[c] = i\n",
    "\n",
    "    sim_scores = [(i, c) for i, c in enumerate(cosine_matrix[0])]\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores = [(news2id[i], score) for i, score in sim_scores[0:5]]\n",
    "\n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num in range(9747):\n",
    "    sim_scores = aaa(num)\n",
    "    sim = []\n",
    "    if sim_scores[0][1] > 0.9:\n",
    "        sim.append(sim_scores[0][0])\n",
    "        result = pd.DataFrame({\n",
    "            'CNo' : et_df.iloc[num]['CNo'],\n",
    "            'Subject' : et_df.iloc[num]['Subject'],\n",
    "            'similar' : sim\n",
    "        })\n",
    "        # 바로 저장\n",
    "        result.to_csv(\"./similar_result_90.csv\", encoding='utf-8',mode = 'a', index=False, header=False)"
   ]
  },
  {
   "source": [
    "# 끝"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}